{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e8892f7",
   "metadata": {},
   "source": [
    "### Load torchreid in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869ea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "from torchreid.utils import (\n",
    "    check_isfile, load_pretrained_weights, compute_model_complexity\n",
    ")\n",
    "from torchreid.models import build_model\n",
    "\n",
    "model_name = \"osnet_x0_25\"\n",
    "model_path = \"/home/ubuntu/workspace/ywshin/construct/Yolov5_StrongSORT_OSNet/weights/osnet_x0_25_msmt17.pt\"\n",
    "device = \"cuda:0\"\n",
    "\n",
    "model = build_model(\n",
    "            model_name,\n",
    "            num_classes=1,\n",
    "            pretrained=not (model_path and check_isfile(model_path)),\n",
    "            use_gpu=device.startswith('cuda')\n",
    "        )\n",
    "\n",
    "if model_path and check_isfile(model_path):\n",
    "    load_pretrained_weights(model, model_path)\n",
    "\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57d621a",
   "metadata": {},
   "source": [
    "### Check Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbbb415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with torch.no_grad():\n",
    "    rslt1 = model(dummy_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a89644",
   "metadata": {},
   "source": [
    "### Convert to ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d2c3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.ones(1, 3, 256, 128).cuda()\n",
    "\n",
    "torch.onnx.export(model,         # model being run \n",
    "         dummy_input,       # model input (or a tuple for multiple inputs) \n",
    "         \"torchreid.onnx\",       # where to save the model  \n",
    "         export_params=True,  # store the trained parameter weights inside the model file \n",
    "         opset_version=11,\n",
    "         do_constant_folding=False,# the ONNX version to export the model to   # whether to execute constant folding for optimization \n",
    "         input_names = [\"input\"],   # the model's input names \n",
    "         output_names = [\"features\"],\n",
    "         dynamic_axes = {'input' : {0 : 'batch_size', 2: \"height\", 3: \"width\"},    # variable length axes \n",
    "                         'features' : {0 : 'batch_size', 2: \"height\", 3: \"width\"}})    # variable length axes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0a5824",
   "metadata": {},
   "source": [
    "### Check onnx Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a19f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "\n",
    "# onnxruntime-gpu version must be compatible to the cuda version\n",
    "print(ort.__version__)\n",
    "\n",
    "# Check if ort is using GPU\n",
    "print(ort.get_device())\n",
    "\n",
    "# Load onnx model using CUDA\n",
    "ort_sess = ort.InferenceSession('torchreid.onnx', providers=['CUDAExecutionProvider'])\n",
    "\n",
    "rslt2 = ort_sess.run(None, {'input': dummy_input.cpu().detach().numpy()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e24ebe7",
   "metadata": {},
   "source": [
    "### TensorRT Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f968cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from PIL import ImageDraw\n",
    "\n",
    "# from data_processing import PreprocessYOLO, PostprocessYOLO, ALL_CATEGORIES\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"tensorrt/\")\n",
    "import samples.python.common as common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950ca9f7",
   "metadata": {},
   "source": [
    "### Set Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4448ebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger()\n",
    "\n",
    "def get_engine(onnx_file_path, engine_file_path=\"\"):\n",
    "    \"\"\"Attempts to load a serialized engine if available, otherwise builds a new TensorRT engine and saves it.\"\"\"\n",
    "    def build_engine():\n",
    "        \"\"\"Takes an ONNX file and creates a TensorRT engine to run inference with\"\"\"\n",
    "        with trt.Builder(TRT_LOGGER) as builder, builder.create_network(common.EXPLICIT_BATCH) as network, builder.create_builder_config() as config, trt.OnnxParser(network, TRT_LOGGER) as parser, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "            config.max_workspace_size = 1 << 28 # 256MiB\n",
    "            # config.set_flag(trt.BuilderFlag.FP16)\n",
    "            builder.max_batch_size = 1\n",
    "            # Parse model file\n",
    "            if not os.path.exists(onnx_file_path):\n",
    "                print('ONNX file {} not found, please run yolov3_to_onnx.py first to generate it.'.format(onnx_file_path))\n",
    "                exit(0)\n",
    "            print('Loading ONNX file from path {}...'.format(onnx_file_path))\n",
    "            with open(onnx_file_path, 'rb') as model:\n",
    "                print('Beginning ONNX file parsing')\n",
    "                if not parser.parse(model.read()):\n",
    "                    print ('ERROR: Failed to parse the ONNX file.')\n",
    "                    for error in range(parser.num_errors):\n",
    "                        print (parser.get_error(error))\n",
    "                    return None\n",
    "            # The actual yolov3.onnx is generated with batch size 64. Reshape input to batch size 1\n",
    "            network.get_input(0).shape = [1, 3, 256, 128]\n",
    "            print('Completed parsing of ONNX file')\n",
    "            print('Building an engine from file {}; this may take a while...'.format(onnx_file_path))\n",
    "            \n",
    "            plan = builder.build_serialized_network(network, config)\n",
    "            # engine = builder.build_cuda_engine(network)\n",
    "            \n",
    "            engine = runtime.deserialize_cuda_engine(plan)\n",
    "            print(\"Completed creating Engine\")\n",
    "            with open(engine_file_path, \"wb\") as f:\n",
    "                f.write(plan)\n",
    "            return engine\n",
    "\n",
    "    if os.path.exists(engine_file_path):\n",
    "        # If a serialized engine exists, use it instead of building an engine.\n",
    "        print(\"Reading engine from file {}\".format(engine_file_path))\n",
    "        with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "            return runtime.deserialize_cuda_engine(f.read())\n",
    "    else:\n",
    "        return build_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e7de56",
   "metadata": {},
   "source": [
    "### Generate trt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_file_path = 'torchreid.onnx'\n",
    "engine_file_path = 'torchreid_256X128_bs_16.trt'\n",
    "\n",
    "get_engine(onnx_file_path, engine_file_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2b8d1e",
   "metadata": {},
   "source": [
    "### Simple Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e17f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_file_path = 'torchreid_256X128_bs_16.trt'\n",
    "with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "    engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    \n",
    "context = engine.create_execution_context()\n",
    "# trt_outputs = []\n",
    "inputs, outputs, bindings, stream = common.allocate_buffers(engine)\n",
    "\n",
    "inputs[0].host = torch.randn(1,3,256,128).numpy().astype(np.float32)\n",
    "trt_outputs = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:owod]",
   "language": "python",
   "name": "conda-env-owod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
