{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c164e87d",
   "metadata": {},
   "source": [
    "# YOLOP conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43016bac",
   "metadata": {},
   "source": [
    "### Install necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c46ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnxruntime-gpu\n",
    "# !pip install onnx-simplifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7319b",
   "metadata": {},
   "source": [
    "### Load Torch Model and convert to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e57c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import onnxsim\n",
    "import os\n",
    "from lib.models import get_net\n",
    "from lib.utils.utils import select_device\n",
    "from lib.config import cfg\n",
    "import torch\n",
    "\n",
    "\n",
    "save_dir = \"/home/ubuntu/workspace/ywshin/construct/YOLOP/onnx\"\n",
    "onnx_path = os.path.join(save_dir, \"yolopv2.onnx\")\n",
    "yolop_weight = \"/home/ubuntu/workspace/ywshin/construct/YOLOP/runs/Patrasche/221014_from_scratch/epoch-400.pth\"\n",
    "inputs = torch.randn(1, 3, 384, 640)\n",
    "\n",
    "do_simplify = True\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = get_net(cfg)\n",
    "checkpoint = torch.load(yolop_weight, map_location= device)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model.eval()\n",
    "\n",
    "\n",
    "print(f\"Converting to {onnx_path}\")\n",
    "torch.onnx.export(model, inputs, onnx_path,\n",
    "                  verbose=False, opset_version=12, input_names=['images'],\n",
    "                  output_names=['det_out', 'drive_area_seg', 'lane_line_seg'])\n",
    "print('convert', onnx_path, 'to onnx finish!!!')\n",
    "# Checks\n",
    "model_onnx = onnx.load(onnx_path)  # load onnx model\n",
    "onnx.checker.check_model(model_onnx)  # check onnx model\n",
    "print(onnx.helper.printable_graph(model_onnx.graph))  # print\n",
    "\n",
    "onnx.save(model_onnx, onnx_path)\n",
    "\n",
    "if do_simplify:\n",
    "    print(f'simplifying with onnx-simplifier {onnxsim.__version__}...')\n",
    "    model_onnx, check = onnxsim.simplify(model_onnx, check_n=3)\n",
    "    assert check, 'assert check failed'\n",
    "    \n",
    "\n",
    "x = inputs.cpu().numpy()\n",
    "try:\n",
    "    sess = ort.InferenceSession(onnx_path, providers=[\"CUDAExecutionProvider\", \"TensorrtExecutionProvider\"])\n",
    "\n",
    "    for ii in sess.get_inputs():\n",
    "        print(\"Input: \", ii)\n",
    "    for oo in sess.get_outputs():\n",
    "        print(\"Output: \", oo)\n",
    "\n",
    "    print('read onnx using onnxruntime sucess')\n",
    "except Exception as e:\n",
    "    print('read failed')\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19746947",
   "metadata": {},
   "source": [
    "### Load Onnx Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576da934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy input\n",
    "dummy_input = torch.randn(1, 3, 384, 640).numpy()\n",
    "\n",
    "# Load onnx model using CUDA\n",
    "ort_sess = ort.InferenceSession('/home/ubuntu/workspace/ywshin/construct/YOLOP/onnx/yolopv2.onnx', providers=['CUDAExecutionProvider'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9de9d",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7fcd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "outputs = ort_sess.run(None, {'images': dummy_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1ce7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs[4].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx",
   "language": "python",
   "name": "onnx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
