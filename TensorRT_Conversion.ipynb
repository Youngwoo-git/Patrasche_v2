{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "918169ee",
   "metadata": {},
   "source": [
    "# TensorRT Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f068ea",
   "metadata": {},
   "source": [
    "### Check tensorrt version: has to be HIGHER than ver 8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f68dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.0.1.6'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "trt.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fa45dc",
   "metadata": {},
   "source": [
    "### Do Constant Folding with Polygraphy (onnx-surgeon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76267ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!polygraphy surgeon sanitize --fold-constants \"weights/yolopv2.onnx\" -o \"weights/yolopv2_folded.onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3910a4fd",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3117ccc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ubuntu/Desktop/workspace/patrasche_tensorrt', '/usr/bin', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '', '/home/ubuntu/.local/lib/python3.6/site-packages', '/usr/local/lib/python3.6/dist-packages', '/usr/local/lib/python3.6/dist-packages/pycuda-2022.1-py3.6-linux-aarch64.egg', '/usr/local/lib/python3.6/dist-packages/appdirs-1.4.4-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/pytools-2022.1.12-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/typing_extensions-4.2.0-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/platformdirs-2.5.2-py3.6.egg', '/home/ubuntu/Desktop/workspace/patrasche/deep-person-reid', '/usr/local/lib/python3.6/dist-packages/imageio-2.19.3-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/isort-4.3.21-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/yapf-0.32.0-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/flake8-4.0.1-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/yacs-0.1.8-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/tb_nightly-2.10.0a20220706-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/h5py-3.7.0-py3.6-linux-aarch64.egg', '/usr/local/lib/python3.6/dist-packages/pyflakes-2.4.0-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/pycodestyle-2.8.0-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/mccabe-0.6.1-py3.6.egg', '/usr/local/lib/python3.6/dist-packages/importlib_metadata-4.2.0-py3.6.egg', '/usr/lib/python3/dist-packages', '/usr/lib/python3.6/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/home/ubuntu/.ipython', '../patrasche/tensorrt/']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from PIL import ImageDraw\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"../patrasche/tensorrt/\")\n",
    "import samples.python.common as common\n",
    "\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f384be41",
   "metadata": {},
   "source": [
    "### Load Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5df3a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger()\n",
    "\n",
    "def get_engine(onnx_file_path, engine_file_path=\"\"):\n",
    "    \"\"\"Attempts to load a serialized engine if available, otherwise builds a new TensorRT engine and saves it.\"\"\"\n",
    "    def build_engine():\n",
    "        \"\"\"Takes an ONNX file and creates a TensorRT engine to run inference with\"\"\"\n",
    "        with trt.Builder(TRT_LOGGER) as builder, builder.create_network(common.EXPLICIT_BATCH) as network, builder.create_builder_config() as config, trt.OnnxParser(network, TRT_LOGGER) as parser, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "            config.max_workspace_size = 1 << 28 # 256MiB\n",
    "            config.set_flag(trt.BuilderFlag.FP16)\n",
    "            builder.max_batch_size = 1\n",
    "            # Parse model file\n",
    "            if not os.path.exists(onnx_file_path):\n",
    "                print('ONNX file {} not found, please run yolov3_to_onnx.py first to generate it.'.format(onnx_file_path))\n",
    "                exit(0)\n",
    "            print('Loading ONNX file from path {}...'.format(onnx_file_path))\n",
    "            with open(onnx_file_path, 'rb') as model:\n",
    "                print('Beginning ONNX file parsing')\n",
    "                if not parser.parse(model.read()):\n",
    "                    print ('ERROR: Failed to parse the ONNX file.')\n",
    "                    for error in range(parser.num_errors):\n",
    "                        print (parser.get_error(error))\n",
    "                    return None\n",
    "            # The actual yolov3.onnx is generated with batch size 64. Reshape input to batch size 1\n",
    "            network.get_input(0).shape = [1, 3, 384, 640]\n",
    "            print('Completed parsing of ONNX file')\n",
    "            print('Building an engine from file {}; this may take a while...'.format(onnx_file_path))\n",
    "            \n",
    "            plan = builder.build_serialized_network(network, config)\n",
    "            # engine = builder.build_cuda_engine(network)\n",
    "            \n",
    "            engine = runtime.deserialize_cuda_engine(plan)\n",
    "            print(\"Completed creating Engine\")\n",
    "            with open(engine_file_path, \"wb\") as f:\n",
    "                f.write(plan)\n",
    "            return engine\n",
    "\n",
    "    if os.path.exists(engine_file_path):\n",
    "        # If a serialized engine exists, use it instead of building an engine.\n",
    "        \n",
    "        trt.init_libnvinfer_plugins(TRT_LOGGER, \"\")\n",
    "        print(\"Reading engine from file {}\".format(engine_file_path))\n",
    "        with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "            return runtime.deserialize_cuda_engine(f.read())\n",
    "    else:\n",
    "        return build_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2947abe9",
   "metadata": {},
   "source": [
    "### Convert Onnx to TensorRT if not converted yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "066f682f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ONNX file from path weights/yolop_folded.onnx...\n",
      "Beginning ONNX file parsing\n",
      "Completed parsing of ONNX file\n",
      "Building an engine from file weights/yolop_folded.onnx; this may take a while...\n",
      "Completed creating Engine\n"
     ]
    }
   ],
   "source": [
    "onnx_file_path = 'weights/yolopv2_folded.onnx'\n",
    "engine_file_path = 'weights/yolopv2.trt'\n",
    "\n",
    "engine = get_engine(onnx_file_path, engine_file_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21614f54",
   "metadata": {},
   "source": [
    "### Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1723add3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy input\n",
    "dummy_input = np.zeros((1,3, 384, 640))\n",
    "dummy_input = np.expand_dims(dummy_input, axis=0)\n",
    "dummy_input = dummy_input.astype(np.float32)\n",
    "\n",
    "# Load TensorRT Model\n",
    "engine = get_engine(onnx_file_path, engine_file_path) \n",
    "\n",
    "# Prepare Context\n",
    "context = engine.create_execution_context()\n",
    "trt_outputs = []\n",
    "inputs, outputs, bindings, stream = common.allocate_buffers(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76294c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Input\n",
    "inputs[0].host = dummy_input\n",
    "\n",
    "# Run Inference\n",
    "trt_outputs = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)\n",
    "# 0: det_out (1,384,640)\n",
    "# 1: drive_area_seg (46035, 4)\n",
    "# 2: lane_line_seg (46035, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3491f737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1163520,)\n",
      "(290880,)\n",
      "(72720,)\n",
      "(1527120,)\n",
      "(491520,)\n",
      "(491520,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(trt_outputs)):\n",
    "    print(trt_outputs[i].shape)\n",
    "# trt_outputs[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7818847",
   "metadata": {},
   "source": [
    "### Get Segmentation Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d951af",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_raw = trt_outputs[0]\n",
    "seg_result = np.reshape(seg_raw,(1,384,640))\n",
    "seg_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
